{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c822c26-6bbc-4958-b0e5-ec2a71d78230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed : xtrain, xtest, ytrain, ytest\n",
      "(74736, 13) (18684, 13) (74736,) (18684,)\n"
     ]
    }
   ],
   "source": [
    "%run ./Preprocessing.ipynb\n",
    "\n",
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, TimeSeriesSplit, KFold\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a037789-1823-4d0d-8a47-259bfbe004b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66d7c2b4-5e2d-45f3-8606-f7e756a474ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_grid = {\n",
    "            'cv': KFold(n_splits=10, random_state=None, shuffle=True),\n",
    "            'number_of_trials': 100,\n",
    "            'time_constraint': 60 * 1\n",
    "        }\n",
    "\n",
    "static_param = {\n",
    "            \"penalty\": 'elasticnet',\n",
    "             'dual': False,\n",
    "             'solver':'saga'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd5e0dea-1f21-4c2e-aa3f-926721a6b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    '''\n",
    "    Objective function to optimise the hyperparamers of Logistic Regression \n",
    "    Args:\n",
    "         trial object (object): Trials evaluating an objective function. \n",
    "         This object provides interfaces to get parameter suggestion, manage the trialâ€™s state, and set/get user-defined attributes of the trial.\n",
    "\n",
    "    Returns:\n",
    "          Study  (object): Trained Study Object\n",
    "    '''  \n",
    "    \n",
    "    param_grid = {\n",
    "                \"intercept_scaling\": trial.suggest_float(\"intercept_scaling\", 0.1, 1.0),\n",
    "                \"max_iter\": trial.suggest_float(\"max_iter\", 300, 300),\n",
    "                \"l1_ratio\": trial.suggest_float(\"l1_ratio\", 0.001, 0.9999)\n",
    "            }\n",
    "\n",
    "    full_grid = {**param_grid, **static_param}\n",
    "\n",
    "    cv = cross_val_score(estimator=lr,\n",
    "                                X=xtrain,\n",
    "                                y=ytrain,\n",
    "                                cv= opt_grid['cv'],\n",
    "                                scoring='roc_auc',\n",
    "                                verbose=True)\n",
    "\n",
    "    score = cv.mean()\n",
    "\n",
    "    if trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return score\n",
    "    \n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')\n",
    "study.optimize(objective, n_trials=opt_grid['number_of_trials'], show_progress_bar=False, timeout=opt_grid['time_constraint'])\n",
    "model_parameters = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca9f5b-18c1-4856-9acd-fa607d6f90d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "564265bf-6d52-43f1-996c-bdd4bf42df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instatiate a Logistic Regression Model \n",
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28ae7f84-c5ac-47af-9a25-66facba71f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(intercept_scaling=0.6855164633757622,\n",
       "                   l1_ratio=0.3687970636941655, max_iter=300.0,\n",
       "                   penalty='elasticnet', solver='saga')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the parameters to the tuned parameters from the optuna study\n",
    "lr_model.set_params(**model_parameters, **static_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76cf8457-bda8-4e25-82db-a3a3dee8a9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\.conda\\envs\\jupyter-lab\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_112\\1046512108.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprobs_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpred_lr_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprobs_lr_train\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mmodel_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_xgb' is not defined"
     ]
    }
   ],
   "source": [
    "#Fit the model on the training data\n",
    "model_lr=lr_model.fit(xtrain,ytrain)\n",
    "#Make predictions. \n",
    "pred_lr=model_lr.predict(xtest)\n",
    "probs_lr = model_lr.predict_proba(xtest)[:, 1]\n",
    "\n",
    "pred_lr_train = model_xgb.predict(xtrain)\n",
    "probs_lr_train =  model_xgb.predict_proba(xtrain)[:, 1]\n",
    "\n",
    "print('-----------model_lr, pred_lr, probs_lr loaded-----------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
